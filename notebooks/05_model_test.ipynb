{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ab8d86c-4606-4703-bc77-9c8e5179f6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "# from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baf5be61-7238-4051-9e2f-d96a51b63766",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b012c52b-9fa5-4732-9ae4-ccb166ee63ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "svc = SVC(kernel='sigmoid',gamma=1.0)\n",
    "knc = KNeighborsClassifier()\n",
    "mnb = MultinomialNB()\n",
    "dtc = DecisionTreeClassifier(max_depth=5)\n",
    "abc = AdaBoostClassifier(n_estimators=50, random_state = 32)\n",
    "bc = BaggingClassifier(n_estimators=50, random_state=32)\n",
    "etc = ExtraTreesClassifier(n_estimators = 50, random_state = 32)\n",
    "gbdt = GradientBoostingClassifier(n_estimators = 50,random_state = 32)\n",
    "# xgb = XGBClassifier(n_estimators=50, random_state = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a31c410-39e7-4c6f-b544-d269e488ace2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdls = {\n",
    "    \"mnb\":mnb,\n",
    "    \"lr\":lr,\n",
    "    \"svc\":svc,\n",
    "    \"knc\":knc,\n",
    "    \"dtc\":dtc,\n",
    "    \"abc\":abc,\n",
    "    \"bc\":bc,\n",
    "    \"etc\":etc,\n",
    "    \"gbdt\":gbdt,\n",
    "    # \"xgb\":xgb,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e07a8110-bd05-4898-8198-f9794c8aa606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_mdl(mdl, X_train, y_train, X_test, y_test):\n",
    "#     mdl.fit(X_train, y_train)\n",
    "#     print(\"model trained\")\n",
    "#     y_preds = mdl.predict(X_test)\n",
    "#     return accuracy_score(y_preds, y_test), precision_score(y_preds, y_test)\n",
    "\n",
    "def predict_mdl(mdl, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Trains model and returns (accuracy,precision)\"\"\"\n",
    "    mdl.fit(X_train, y_train)\n",
    "    y_preds = mdl.predict(X_test)\n",
    "\n",
    "    # print('hi')\n",
    "    print(accuracy_score(y_test,y_preds))\n",
    "    print(confusion_matrix(y_test,y_preds))\n",
    "    print(precision_score(y_test,y_preds))\n",
    "\n",
    "    return accuracy_score(y_preds, y_test), precision_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a68c632a-4b63-4ac1-abfe-0ff014e80e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_mdl(lr,X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3207e55-d57f-49ed-bfed-e82b386aad0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3940b25-4e94-4e7f-8df8-693da08cfbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/spam_new.csv',encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71a05f35-4593-4a74-8dcd-440076bb4099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3214731-d302-47c5-9620-435f97e8f060",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'v1':'status', 'v2':'sms'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "742aed14-99cb-4e70-b378-404d52e233ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 2','Unnamed: 3', 'Unnamed: 4'], axis= 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e2775ea-6ff5-4697-886a-526e7f114306",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['status'] = df['status'].map({\"ham\":0, \"spam\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e403593c-7cf7-47ca-8f57-4fca6fec0da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from word_process import WordProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f51db8e-cc0d-4c4b-ba57-5c557029c36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wp = WordProcess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f3df03f-c617-47d4-9b8d-11a631d798b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f56ab3b4-842f-479f-ad0d-7fb3e56d90ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aaa82ed0-4797-4ffb-b9df-373e5fdc8921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = CountVectorizer()\n",
    "# cv.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64cb200c-eed7-4da2-b18c-6566682faa21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/suraj/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /Users/suraj/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data] Downloading package stopwords to /Users/suraj/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/suraj/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/suraj/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59c6513c-6d05-47a6-96a4-739270583928",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "def transform_text(text):\n",
    "    text = text.lower()\n",
    "    text = nltk.word_tokenize(text)\n",
    "    \n",
    "    y = []\n",
    "    for i in text:\n",
    "        if i.isalnum():\n",
    "            y.append(i)\n",
    "    \n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    \n",
    "    for i in text:\n",
    "        if i not in stopwords.words('english') and i not in string.punctuation:\n",
    "            y.append(i)\n",
    "            \n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    \n",
    "    for i in text:\n",
    "        y.append(ps.stem(i))\n",
    "    \n",
    "            \n",
    "    return \" \".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0855878-583e-41d4-a3f4-5fb823ed1f36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c8fb641-004a-42af-969b-d325856e6d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['processed'] = df['sms'].apply(wp.process_sent2sent)\n",
    "df['processed'] = df['sms'].apply(transform_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c4ceb11-8adc-4583-a65e-57c0266c1ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['processed'],\n",
    "                                                    df['status'],test_size=0.2, random_state = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8cbd8937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_features=3000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer(max_features=3000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(max_features=3000)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = TfidfVectorizer(max_features=3000)\n",
    "cv.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a46191c9-81b8-4fb2-9e33-6a30294c6a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cv = cv.transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ff6be72-7481-4b4c-a893-bcbdaffa1bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c98233a6-c234-48e7-aeeb-e8e529574048",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cv = np.expand_dims(np.array(y_train),axis=-1)\n",
    "y_test_cv = np.expand_dims(np.array(y_test),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aed2c05d-65e3-48e1-a8cf-4295a01e3a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4457, 3000)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a99b605f-f202-4b32-876d-6ca50703b1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9704035874439462\n",
      "[[969   0]\n",
      " [ 33 113]]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "mnb.fit(X_train_cv,y_train)\n",
    "y_pred2 = mnb.predict(X_test_cv)\n",
    "print(accuracy_score(y_test,y_pred2))\n",
    "print(confusion_matrix(y_test,y_pred2))\n",
    "print(precision_score(y_test,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8ae22439-3371-4197-9519-9903833fe9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9704035874439462\n",
      "[[969   0]\n",
      " [ 33 113]]\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9704035874439462, np.float64(1.0))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lr.fit(X_train_cv,y_train)\n",
    "predict_mdl(mnb,X_train_cv, y_train, X_test_cv, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ad946cd8-adec-4791-8473-c9057c62c00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "54a9a7d4-3c8b-49da-b03b-f565db3272a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_mdl(lr,X_train_cv, y_train, X_test_cv, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "18bc345d-2bff-4676-9382-d9bf24fa4c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---===------===------===------===------===---\n",
      "mnb\n",
      "0.9704035874439462\n",
      "[[969   0]\n",
      " [ 33 113]]\n",
      "1.0\n",
      "0.9704035874439462 1.0\n",
      "\n",
      "---===------===------===------===------===---\n",
      "lr\n",
      "0.9659192825112107\n",
      "[[968   1]\n",
      " [ 37 109]]\n",
      "0.990909090909091\n",
      "0.9659192825112107 0.990909090909091\n",
      "\n",
      "---===------===------===------===------===---\n",
      "svc\n",
      "0.9802690582959641\n",
      "[[967   2]\n",
      " [ 20 126]]\n",
      "0.984375\n",
      "0.9802690582959641 0.984375\n",
      "\n",
      "---===------===------===------===------===---\n",
      "knc\n",
      "0.9192825112107623\n",
      "[[969   0]\n",
      " [ 90  56]]\n",
      "1.0\n",
      "0.9192825112107623 1.0\n",
      "\n",
      "---===------===------===------===------===---\n",
      "dtc\n",
      "0.9354260089686098\n",
      "[[952  17]\n",
      " [ 55  91]]\n",
      "0.8425925925925926\n",
      "0.9354260089686098 0.8425925925925926\n",
      "\n",
      "---===------===------===------===------===---\n",
      "abc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/nlpRpEnv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9730941704035875\n",
      "[[967   2]\n",
      " [ 28 118]]\n",
      "0.9833333333333333\n",
      "0.9730941704035875 0.9833333333333333\n",
      "\n",
      "---===------===------===------===------===---\n",
      "bc\n",
      "0.9659192825112107\n",
      "[[956  13]\n",
      " [ 25 121]]\n",
      "0.9029850746268657\n",
      "0.9659192825112107 0.9029850746268657\n",
      "\n",
      "---===------===------===------===------===---\n",
      "etc\n",
      "0.9820627802690582\n",
      "[[967   2]\n",
      " [ 18 128]]\n",
      "0.9846153846153847\n",
      "0.9820627802690582 0.9846153846153847\n",
      "\n",
      "---===------===------===------===------===---\n",
      "gbdt\n",
      "0.9497757847533632\n",
      "[[965   4]\n",
      " [ 52  94]]\n",
      "0.9591836734693877\n",
      "0.9497757847533632 0.9591836734693877\n"
     ]
    }
   ],
   "source": [
    "names = []\n",
    "accuracies = []\n",
    "precisions = []\n",
    "for name, mdl in mdls.items():\n",
    "    print()\n",
    "    print(\"---===---\"*5)\n",
    "    print(name)\n",
    "    (acc, pre) = predict_mdl(mdl, X_train_cv, y_train, X_test_cv, y_test)\n",
    "    print(acc, pre)\n",
    "    names.append(name)\n",
    "    accuracies.append(acc)\n",
    "    precisions.append(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "67e1b5fb-7dd9-4993-b2dd-4ee974573897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['mnb', 'lr', 'svc', 'knc', 'dtc', 'abc', 'bc', 'etc', 'gbdt'],\n",
       " [0.9704035874439462,\n",
       "  0.9659192825112107,\n",
       "  0.9802690582959641,\n",
       "  0.9192825112107623,\n",
       "  0.9354260089686098,\n",
       "  0.9730941704035875,\n",
       "  0.9659192825112107,\n",
       "  0.9820627802690582,\n",
       "  0.9497757847533632],\n",
       " [np.float64(1.0),\n",
       "  np.float64(0.990909090909091),\n",
       "  np.float64(0.984375),\n",
       "  np.float64(1.0),\n",
       "  np.float64(0.8425925925925926),\n",
       "  np.float64(0.9833333333333333),\n",
       "  np.float64(0.9029850746268657),\n",
       "  np.float64(0.9846153846153847),\n",
       "  np.float64(0.9591836734693877)])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names,accuracies, precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2241eaaa-dc78-4538-9d80-7ad796758375",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = pd.DataFrame({\"models\":names,\"accuracy\":accuracies,\"precision\":precisions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "aceca8bf-a769-4262-b8af-880e5a5d7dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rec['yt_tfidf_m3k_acc'] = accuracies\n",
    "# rec['yt_tfidf_m3k_prec'] = precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "442dab99-3792-4b0a-8fad-849d23ecd08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.965919</td>\n",
       "      <td>0.746575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svc</td>\n",
       "      <td>0.980269</td>\n",
       "      <td>0.863014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>knc</td>\n",
       "      <td>0.913901</td>\n",
       "      <td>0.342466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mnb</td>\n",
       "      <td>0.970404</td>\n",
       "      <td>0.773973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dtc</td>\n",
       "      <td>0.935426</td>\n",
       "      <td>0.623288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abc</td>\n",
       "      <td>0.973094</td>\n",
       "      <td>0.808219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bc</td>\n",
       "      <td>0.965919</td>\n",
       "      <td>0.828767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>etc</td>\n",
       "      <td>0.982063</td>\n",
       "      <td>0.876712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.949776</td>\n",
       "      <td>0.643836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.967713</td>\n",
       "      <td>0.780822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  models  accuracy  precision\n",
       "0     lr  0.965919   0.746575\n",
       "1    svc  0.980269   0.863014\n",
       "2    knc  0.913901   0.342466\n",
       "3    mnb  0.970404   0.773973\n",
       "4    dtc  0.935426   0.623288\n",
       "5    abc  0.973094   0.808219\n",
       "6     bc  0.965919   0.828767\n",
       "7    etc  0.982063   0.876712\n",
       "8   gbdt  0.949776   0.643836\n",
       "9    xgb  0.967713   0.780822"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rec.sort_values(by=['yt_tfidf_m3k_prec','yt_tfidf_m3k_acc'],ascending=[False,False])\n",
    "rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b56d4d91-14f6-40dd-9de8-e6e2f1c4108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rec.to_csv(\"spam_lemm.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a1f5866e-2463-42c5-a8dc-5d43464ad667",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fc6d47ba-2a2f-4377-a960-3e114cb02f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.predict(cv.transform([wp.process_sent2sent(text)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "904e9209-0582-48ff-b0e3-5c42c33da8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = df[df['status']==1].iloc[98]['sms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6376dd43-d896-4439-bd6c-700f5dd3759c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = 70\n",
    "text = X_test.iloc[ind]\n",
    "y_test.iloc[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c3345a00-4222-4466-9285-bdf9f5c58597",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/suraj/nltk_data'\n    - '/Applications/anaconda3/envs/aimlEnv/nltk_data'\n    - '/Applications/anaconda3/envs/aimlEnv/share/nltk_data'\n    - '/Applications/anaconda3/envs/aimlEnv/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtransform_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msms\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[34], line 3\u001b[0m, in \u001b[0;36mtransform_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform_text\u001b[39m(text):\n\u001b[1;32m      2\u001b[0m     text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m----> 3\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     y \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m text:\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/aimlEnv/lib/python3.10/site-packages/nltk/tokenize/__init__.py:129\u001b[0m, in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    131\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[1;32m    132\u001b[0m     ]\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/aimlEnv/lib/python3.10/site-packages/nltk/tokenize/__init__.py:106\u001b[0m, in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     97\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokenizers/punkt/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlanguage\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pickle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/aimlEnv/lib/python3.10/site-packages/nltk/data.py:750\u001b[0m, in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<<Loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    749\u001b[0m \u001b[38;5;66;03m# Load the resource.\u001b[39;00m\n\u001b[0;32m--> 750\u001b[0m opened_resource \u001b[38;5;241m=\u001b[39m \u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m     resource_val \u001b[38;5;241m=\u001b[39m opened_resource\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/aimlEnv/lib/python3.10/site-packages/nltk/data.py:876\u001b[0m, in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    873\u001b[0m protocol, path_ \u001b[38;5;241m=\u001b[39m split_resource_url(resource_url)\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m protocol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnltk\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mopen()\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;66;03m# urllib might not use mode='rb', so handle this one ourselves:\u001b[39;00m\n\u001b[1;32m    879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m find(path_, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mopen()\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/aimlEnv/lib/python3.10/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/suraj/nltk_data'\n    - '/Applications/anaconda3/envs/aimlEnv/nltk_data'\n    - '/Applications/anaconda3/envs/aimlEnv/share/nltk_data'\n    - '/Applications/anaconda3/envs/aimlEnv/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "transform_text(df['sms'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "9e83d1d3-203a-4e9d-a556-efae7589c08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "\n",
    "class WordProcess1:\n",
    "    def __init__(self):\n",
    "        # self.lemm = WordNetLemmatizer()\n",
    "        self.lemm = PorterStemmer()\n",
    "        nltk.download(\"stopwords\")\n",
    "        nltk.download('wordnet')\n",
    "        nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "    def get_wordnet_pos(self, pos):\n",
    "        if pos.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif pos.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif pos.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif pos.startswith(\"R\"):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            return wordnet.NOUN\n",
    "        \n",
    "    def process_sentence(self, sent):\n",
    "        # lowercasing\n",
    "        sen = sent.lower()\n",
    "\n",
    "        # tokenizing\n",
    "        tkns = wordpunct_tokenize(sen)\n",
    "\n",
    "        # removing stopwords and punctuations\n",
    "        stops = stopwords.words('english')\n",
    "        stops.extend([\"..\",\"...\",])\n",
    "        puncts = string.punctuation\n",
    "        clean = []\n",
    "        for word in tkns:\n",
    "            if word not in stops and word not in puncts:\n",
    "            # if len(word) > 1 and word not in stops and word not in puncts:\n",
    "                clean.append(word)\n",
    "\n",
    "        # word lemmatization\n",
    "        word_tags = nltk.pos_tag(clean)\n",
    "        word_lemm = []\n",
    "        for word,tag in word_tags:\n",
    "            # word_lemm.append(self.lemm.lemmatize(word,self.get_wordnet_pos(tag)))\n",
    "            word_lemm.append(self.lemm.stem(word))\n",
    "\n",
    "        sen = None\n",
    "        tkns = None\n",
    "        clean = None\n",
    "        word_tags = None\n",
    "\n",
    "        return word_lemm\n",
    "    \n",
    "    def process_sent2sent(self, sent):\n",
    "        return \" \".join(self.process_sentence(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1e6c19a3-37eb-4f38-92e3-ad6bbb32582d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/suraj/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/suraj/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/suraj/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "wp = WordProcess1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "c8335501-9042-4070-94ab-598922557934",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec.to_csv(\"spam_models_v2-1Feb-0128.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "09281df6-773c-4108-ab63-6513131895e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "812d35ec-1bb2-4a9e-9606-6cc57886061e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(mnb, open(\"spam_mnb_model_1Feb_0202.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a148a785-311e-4004-80fa-00dfbefb1ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(cv,open(\"spam_tfidf_vec_1Feb_0202.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d926e08e-3ce7-458a-9443-a4a3cf9706d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
